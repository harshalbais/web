<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>üåç Multilingual AI Voice Assistant</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <!-- Tailwind -->
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- Bootstrap Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.css">
  <style>
    .status-dot { width: 10px; height: 10px; border-radius: 9999px; display: inline-block; margin-right: 8px; }
  </style>
</head>
<body class="bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500 min-h-screen flex items-center justify-center font-sans">

  <div class="bg-white rounded-2xl shadow-2xl p-6 md:p-8 w-full max-w-lg">
    <h2 class="text-2xl font-bold mb-4 flex items-center gap-2">
      <i class="bi bi-mic-fill text-purple-600"></i> Multilingual AI Voice Assistant
    </h2>

    <!-- Language Selector -->
    <label for="langSelect" class="block text-sm font-medium text-gray-700 mb-2">Choose Language</label>
    <select id="langSelect"
            class="w-full p-3 rounded-lg border border-gray-300 focus:ring-2 focus:ring-purple-500 focus:border-purple-500 mb-4"
            aria-label="Choose language">
      <option value="en-US">English (US)</option>
      <option value="hi-IN">Hindi</option>
      <option value="mr-IN">Marathi</option>
      <option value="fr-FR">French</option>
      <option value="de-DE">German</option>
    </select>

    <!-- Controls -->
    <div class="flex items-center gap-3 mb-4">
      <button id="btnStart"
              class="flex items-center gap-2 bg-green-500 text-white px-5 py-2 rounded-xl hover:bg-green-600 transition shadow-lg disabled:opacity-50 disabled:cursor-not-allowed"
              aria-label="Start listening">
        <i class="bi bi-play-fill text-xl"></i> Start
      </button>
      <button id="btnStop"
              class="flex items-center gap-2 bg-red-500 text-white px-5 py-2 rounded-xl hover:bg-red-600 transition shadow-lg disabled:opacity-50 disabled:cursor-not-allowed"
              aria-label="Stop listening" disabled>
        <i class="bi bi-stop-fill text-xl"></i> Stop
      </button>
      <span id="status" class="text-sm text-gray-700 flex items-center">
        <span id="statusDot" class="status-dot bg-gray-300" aria-hidden="true"></span>
        <span id="statusText">Idle.</span>
      </span>
    </div>

    <!-- Tip -->
    <div class="text-xs text-gray-600 mb-3">
      Tip: First time, your browser will ask for microphone permission. Use Chrome/Edge desktop for best results.
    </div>

    <!-- Chat -->
    <div id="chatBox" class="bg-gray-50 rounded-xl p-4 h-80 overflow-y-auto shadow-inner space-y-3 text-sm" role="log" aria-live="polite"></div>
  </div>

  <script>
    // ---------- Globals ----------
    let recognition = null;
    let isRecognizing = false;
    let manuallyStopped = false;
    let voicesReady = false;

    const RESTART_DELAY_MS = 900;

    const btnStart = document.getElementById("btnStart");
    const btnStop = document.getElementById("btnStop");
    const chatBox = document.getElementById("chatBox");
    const statusText = document.getElementById("statusText");
    const statusDot = document.getElementById("statusDot");
    const langSelect = document.getElementById("langSelect");

    // ---------- UI helpers ----------
    function setStatus(mode, text) {
      // mode: 'idle' | 'listening' | 'reconnecting' | 'stopped' | 'error'
      const colors = {
        idle: "bg-gray-300",
        listening: "bg-green-500",
        reconnecting: "bg-yellow-400",
        stopped: "bg-red-500",
        error: "bg-red-600"
      };
      statusDot.className = `status-dot ${colors[mode] || colors.idle}`;
      statusText.textContent = text;
    }

    function setButtons(listening) {
      // When listening: disable Start, enable Stop
      btnStart.disabled = listening;
      btnStop.disabled = !listening;
    }

    function escapeHtml(str) {
      return String(str).replace(/[&<>"']/g, s => ({
        "&": "&amp;", "<": "&lt;", ">": "&gt;", '"': "&quot;", "'": "&#39;"
      }[s]));
    }

    function addBubble(sender, text, side = "left") {
      const wrapper = document.createElement("div");
      wrapper.className = `max-w-[85%] ${side === "left" ? "self-start" : "self-end"} flex`;
      wrapper.innerHTML = `
        <div class="${side === "left" ? "bg-white" : "bg-purple-100"} rounded-2xl px-3 py-2 shadow text-gray-800">
          <span class="font-semibold">${escapeHtml(sender)}:</span> ${escapeHtml(text)}
        </div>
      `;
      chatBox.appendChild(wrapper);
      chatBox.scrollTop = chatBox.scrollHeight;
    }

    // ---------- Speech Synthesis (TTS) ----------
    function chooseVoice(lang) {
      const list = window.speechSynthesis.getVoices() || [];
      // Exact match first
      let v = list.find(vo => vo.lang === lang);
      if (v) return v;
      // Fallback: same base language (e.g., 'hi' from 'hi-IN')
      const base = lang.split("-")[0];
      v = list.find(vo => vo.lang && vo.lang.startsWith(base));
      return v || null;
    }

    function speakText(text, lang) {
      if (!("speechSynthesis" in window)) return; // no TTS support
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = lang;
      const voice = chooseVoice(lang);
      if (voice) utter.voice = voice;
      // Slightly slower for clarity
      utter.rate = 0.98;
      try { window.speechSynthesis.speak(utter); } catch {}
    }

    // Load voices list (Chrome fires this async)
    if ("speechSynthesis" in window) {
      window.speechSynthesis.onvoiceschanged = () => { voicesReady = true; };
      // Trigger load
      window.speechSynthesis.getVoices();
    }

    // ---------- Speech Recognition ----------
    function makeRecognizer() {
      const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SR) return null;
      const rec = new SR();
      rec.lang = langSelect.value;
      rec.continuous = true;
      rec.interimResults = false;
      return rec;
    }

    function startRecognition() {
      if (isRecognizing) return;

      const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SR) {
        addBubble("System", "Your browser does not support SpeechRecognition. Please use Chrome or Edge on desktop.", "left");
        setStatus("error", "SpeechRecognition not supported.");
        return;
      }

      manuallyStopped = false;

      recognition = makeRecognizer();
      if (!recognition) {
        setStatus("error", "Failed to initialize recognition.");
        return;
      }

      recognition.onstart = () => {
        isRecognizing = true;
        setButtons(true);
        setStatus("listening", "Listening‚Ä¶");
      };

      recognition.onresult = (event) => {
        const result = event.results[event.results.length - 1];
        if (!result || !result[0]) return;
        const text = String(result[0].transcript || "").trim();
        if (!text) return;

        // If AI is speaking, stop it so we can listen to user clearly
        if (window.speechSynthesis && window.speechSynthesis.speaking) {
          try { window.speechSynthesis.cancel(); } catch {}
        }

        addBubble("You", text, "right");
        sendToBackend(text, recognition.lang);
      };

      recognition.onerror = (e) => {
        console.warn("Recognition error:", e.error);
        // Some common recoverable errors: "no-speech", "aborted", "audio-capture"
        if (e.error === "not-allowed" || e.error === "service-not-allowed") {
          setStatus("error", "Microphone permission denied.");
          stopRecognition(); // lock it
        }
      };

      recognition.onend = () => {
        isRecognizing = false;
        setButtons(false);

        if (manuallyStopped) {
          setStatus("stopped", "Stopped.");
          return;
        }

        // Auto-reconnect with fresh instance after a small delay
        setStatus("reconnecting", "Reconnecting‚Ä¶");
        setTimeout(() => {
          if (!manuallyStopped && !isRecognizing) {
            startRecognition(); // create a new instance and start again
          }
        }, RESTART_DELAY_MS);
      };

      try {
        recognition.start();
      } catch (err) {
        console.warn("Start error:", err);
        setStatus("error", "Could not start listening.");
      }
    }

    function stopRecognition() {
      manuallyStopped = true;
      if (recognition) {
        try { recognition.stop(); } catch {}
      }
      isRecognizing = false;
      setButtons(false);
      setStatus("stopped", "Stopped.");
    }

    // ---------- Backend ----------
    async function sendToBackend(text, lang) {
      try {
        const res = await fetch("/chat", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ message: text, lang })
        });
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        const data = await res.json();
        const reply = (data && data.reply) ? String(data.reply) : "Sorry, I couldn't process that.";
        addBubble("AI", reply, "left");
        speakText(reply, data.lang || lang);
      } catch (e) {
        console.warn("Fetch error:", e);
        addBubble("System", "Network error. Please check your server and try again.", "left");
      }
    }

    // ---------- Event Bindings ----------
    btnStart.addEventListener("click", startRecognition);
    btnStop.addEventListener("click", stopRecognition);

    // Stop SR + TTS on page unload
    window.addEventListener("beforeunload", () => {
      manuallyStopped = true;
      if (recognition) { try { recognition.stop(); } catch {} }
      if (window.speechSynthesis && window.speechSynthesis.speaking) {
        try { window.speechSynthesis.cancel(); } catch {}
      }
    });
  </script>
</body>
</html>
